# Amazon-Vine Analysis: Creating a Database of Amazon Reviews and Looking for Bias in Paid Reviews

## Overview
The phrase “big data” refers to data sets that are large enough to require processing power above and beyond that which is associated with a single/stand alone processor or personal computer.  Traditionally, such data sets were treated using “Hadoop” - a collection of open-source software utilities that facilitates using a network of computers – but it has become far more common to employ Google Colab in conjunction with “Spark” and Amazon Web Services (AWS) to address the processing requirements associated with “big data”.  The purpose of this analysis was to use Google Colab and Spark to access Amazon Reviews data, create tables corresponding to subsets of that data to be imported into an AWS hosted PostgresSQL database and also analyse the data to ascertain the likelihood of bias in paid reviews generated by the Amazon Vine program.

## Results
Upon examination of available Amazon Review data sets, the data set pertaining to reviews of electronics was selected and, using spark, imported into a Google Colab notebook.  Using the appropriate commands, groups of columns were selected from the data set to create tables which, following the specified filtering to eliminate duplicate records and problematic data, were exported into corresponding tables in an AWS hosted PostgresSQL database (See Figure 1).

### Figure 1: Tables Constructed and Imported in to AWS Hosted PostgresSQL Database
![]( https://github.com/Scruffy-Bearie/Amazon_Vine_Analysis/blob/main/IMAGES/Image3.png)

To investigate the possibility of bias in paid Amazon Reviews, the “Vine_Table” created for the PostgresSQL data base was filtered according to specified criteria to eliminate problematic data points and the remaining data filtered so as to perform calculations to determine: (1) The percent of paid five star reviews and (2) the percent of unpaid five star reviews(see Figures 2 and 3).

### Figure 2: Analysis of Paid Reviews
![]( https://github.com/Scruffy-Bearie/Amazon_Vine_Analysis/blob/main/IMAGES/Image1.png)

### Figure 3: Analysis of Unpaid Reviews
![]( https://github.com/Scruffy-Bearie/Amazon_Vine_Analysis/blob/main/IMAGES/Image2.png)

To obtain a more robust analysis of potential bias in paid reviews, the filtered vine data was, via two steps, imported in RStudio and scrutinized using a two sample t-test (see Figure 4).

### Figure 4: Analysis of Paid and Unpaid Reviews in RStudio
![]( https://github.com/Scruffy-Bearie/Amazon_Vine_Analysis/blob/main/IMAGES/Image4.png) 

## Summary
Analysis of the results acquired provided the following information:

•	Total number of Vine (paid) reviews: 1080

•	Total number of 5 star Vine (paid) reviews: 454

•	Percentage of Vine (paid) reviews that were 5 stars: 42 %


•	Total Number of Non-Vine (unpaid) reviews: 49673

•	Total number of 5 star Non-Vine (unpaid) reviews: 23043

•	Percentage of Non-Vine (unpaid) reviews that were 5 stars: 46 %

The results acquired (as displayed above) suggest that there is a “difference” in paid vs. unpaid reviews – the lower percentage of paid 5 star reviews suggesting that paid reviewers may be more critical than unpaid reviewers, but said results are by no means “proof” that there is a statistically significant difference between the paid and unpaid reviews.

In the interests of determining if there was a statistically significant difference between the paid and unpaid reviews, the same data set used to generate the statistics above was imported into RStudio and analysed to determine (1) the mean “star_review” for both the “paid” and “unpaid” categories and (2) the results of a two sample t-test comparing the means for “paid” and “unpaid” reviews (see Figure 4).

The results acquired demonstrate that the mean “star_review” for paid reviews was 4.09 while that for unpaid reviews was 3.65.  The null hypothesis for the t-test comparing the means was that there was no statistically significant difference between the means and the p-value associated with the test, 2.2e-16, suggested that the null hypothesis should be rejected in favour of the alternate: there is a statistically significant difference between the means (the means are not the same).  As such, comparison of the means taken in conjunction with the results of the t-test suggest that there is in fact bias associated with the paid review program in favour of higher reviews on average.

 
